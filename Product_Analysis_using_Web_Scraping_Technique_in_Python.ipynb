{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Product Analysis using Web Scraping Technique in Python.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO5JGz2/FMikcRR4JhqDyrx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MxwdMHujjmx"
      },
      "source": [
        "[Reference](https://chithraprabhap.medium.com/product-analysis-using-web-scrapping-technique-in-python-459a363523e4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmxJZhOigFwl"
      },
      "source": [
        "import bs4\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from urllib.request import urlopen as uReq\n",
        "from bs4 import BeautifulSoup as soup"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOwIKoOygI8p"
      },
      "source": [
        "myurl = 'https://www.flipkart.com/tablets/pr?sid=tyy,hry&marketplace=FLIPKART'\n",
        "uclient = uReq(myurl)\n",
        "page_html = uclient.read()\n",
        "uclient.close()\n",
        "\n",
        "psoup = soup(page_html, 'html.parser')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qv8uolJgNej"
      },
      "source": [
        "page_urls = list()\n",
        "for containers in psoup.findAll('div',{'class':'_2MImiq'}):\n",
        "    a_list = containers.findAll('a',{'class':'ge-49M'})\n",
        "\n",
        "#uncomment and use the below 2 lines to get all the search 10 pages\n",
        "#for a in a_list:\n",
        "# page_urls.append(‘https://www.flipkart.com’+ a[‘href’])\n",
        "\n",
        "\n",
        "#use the below 2 lines to get single search page\n",
        "a= a_list[0]\n",
        "page_urls.append('https://www.flipkart.com'+ a['href'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfBZf8vwgZDk",
        "outputId": "2a587e66-5115-4720-b426-acbe36f43bfa"
      },
      "source": [
        "for url in page_urls:\n",
        "    print(url)\n",
        "    uclient = uReq(url)\n",
        "    page_html = uclient.read()\n",
        "    uclient.close()\n",
        "    psoup = soup(page_html, 'html.parser')\n",
        "\n",
        "prod_urls = list()\n",
        "for containers in psoup.findAll('div',{'class':'_13oc-S'}):\n",
        "    for a in containers:\n",
        "        a_list = a.findAll('a',{'class':'_1fQZEK'})\n",
        "#print(a_list[‘href’])\n",
        "#prod_urls.append(‘https://www.flipkart.com’+ a_list[‘href’])\n",
        "\n",
        "for a in a_list:\n",
        "    prod_urls.append('https://www.flipkart.com'+ a['href'])\n",
        "\n",
        "for p_url in prod_urls:\n",
        "    uclient = uReq(p_url)\n",
        "    page_html = uclient.read()\n",
        "    uclient.close()\n",
        "psoup = soup(page_html, 'html.parser')\n",
        "\n",
        "all_procuct_items = psoup.find('div', attrs={'class' : '_3k-BhJ'})\n",
        "all_procuct_items = all_procuct_items.findAll('tr', attrs={'class' : '_1s_Smc row'})\n",
        "\n",
        "#container variable contains the html of product title which is stored in div tag and class is “_1AtVbE col-12–12”\n",
        "container= psoup.findAll('div',{'class':'_1AtVbE col-12–12'})\n",
        "for product_item in container:\n",
        "    product_dict = dict()\n",
        "    rating_dict= dict()\n",
        "    price_dict = dict()\n",
        "    brandname_dict = dict()\n",
        "\n",
        "    n = product_item.findAll('span',{'class':'B_NuCI'})\n",
        "    p = product_item.findAll('div',{'class':'_30jeq3 _16Jk6d'})\n",
        "    r = product_item.findAll('div',{'class':'_2d4LTz'})\n",
        "\n",
        "    for i in n:\n",
        "        product_dict['name'] = i.text\n",
        "        strtmp = i.text.split(' ')\n",
        "        brandname_dict['brandname'] = strtmp[0]\n",
        "        brandnames_list.append(strtmp[0])\n",
        "        products_list.append(i.text)\n",
        "        for j in p:\n",
        "            jStr = j.text\n",
        "            jStr = jStr.replace('₹', '')\n",
        "            jStr = jStr.replace(',', '')\n",
        "            price_dict['price'] = int( jStr)\n",
        "            prices_list.append(int( jStr))\n",
        "        for k in r:\n",
        "            #print (i.text)\n",
        "            rating_dict['rating'] = k.text\n",
        "            ratings_list.append(k.text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://www.flipkart.com/tablets/pr?sid=tyy%2Chry&marketplace=FLIPKART&page=1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__w4xZfgiz2y"
      },
      "source": [
        "df = pd.DataFrame({'Brand':brandnames_list,\n",
        "                   'Price':prices_list,\n",
        "                   'Ratings':ratings_list,\n",
        "                   'ProductName':products_list})\n",
        "# df.to_csv('export_products_dataframe.csv')\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}